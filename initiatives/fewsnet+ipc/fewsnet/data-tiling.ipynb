{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import json\n",
    "import plotly.express as px\n",
    "import os\n",
    "import rtree\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(bounds, size):\n",
    "    xmin, ymin, xmax, ymax = bounds\n",
    "\n",
    "    length = size\n",
    "    wide = size\n",
    "\n",
    "    cols = list(np.arange(xmin, xmax + size, size))\n",
    "    rows = list(np.arange(ymin, ymax + size, size))\n",
    "\n",
    "    polygons = []\n",
    "    for x in cols[:-1]:\n",
    "        for y in rows[:-1]:\n",
    "            polygons.append(Polygon([(x,y), (x+size, y), (x+size, y+length), (x, y+size)]))\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "    grid = grid.set_crs(epsg=4326)\n",
    "    grid['centroid'] = grid.centroid\n",
    "    grid = grid.to_crs(epsg=4326)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that joins fewsnet data to grid with list of local files\n",
    "dates_list = []\n",
    "unmerged_files = []\n",
    "def join_to_grid(grid_gdf, polygon_file_list):\n",
    "    grid_gdf = grid_gdf.set_geometry('centroid')\n",
    "    grid_gdf = grid_gdf.to_crs(epsg=4326)\n",
    "    filenum = 1\n",
    "    for file in polygon_file_list:\n",
    "        try:\n",
    "            print (\"joining file \" + str(filenum) + \" \" + str(file))\n",
    "            tempgdf = gpd.read_file(file)\n",
    "            tempgdf = tempgdf.to_crs(epsg=4326)\n",
    "            month = file[-9:-7]\n",
    "            year = file[-13:-9]\n",
    "            datestring = year + \"-\" + month\n",
    "            tempgdf = tempgdf.add_suffix(\"-\"+datestring)\n",
    "            tempgdf = tempgdf.rename(columns={\"geometry-\"+datestring: \"geometry\"})\n",
    "            tempgdf = tempgdf.set_geometry('geometry')\n",
    "            # print column name\n",
    "            print (\"CS-\"+year+'-'+month)\n",
    "            # the actual spatial join\n",
    "            grid_gdf = grid_gdf.sjoin(tempgdf, how=\"left\")\n",
    "            print (\"with duplicates dataframe is \" + str(grid_gdf.shape))\n",
    "            grid_gdf = grid_gdf.drop(columns=['index_right'])\n",
    "            # print column names of grid_gdf\n",
    "            # print (grid_gdf.columns)\n",
    "            # this part deals with the merging of columns when reports are from the same year and month\n",
    "            # the result of this is the data is all joined into one column. \n",
    "            # There should not be any duplicate geometries measured in these reports as they are from different regions\n",
    "            # if there are duplicate geometries, the data that was joined first will be kept\n",
    "            # we handle duplicate geometries from the same reports in the next section keeping the higher measurement\n",
    "            if \"CS-\"+datestring+\"_left\" in grid_gdf.columns:\n",
    "                try:\n",
    "                    grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
    "                    grid_gdf = grid_gdf.rename(columns={\"CS-\"+datestring+\"_left\": \"CS-\"+datestring})\n",
    "                    grid_gdf = grid_gdf.drop(columns=[\"CS-\"+datestring+\"_right\"])\n",
    "                except:\n",
    "                    print (\"no column to merge\")\n",
    "                try:\n",
    "                    grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n",
    "                    grid_gdf = grid_gdf.rename(columns={\"HA0-\"+datestring+\"_left\": \"HA0-\"+datestring})\n",
    "                    grid_gdf = grid_gdf.drop(columns=[\"HA0-\"+datestring+\"_right\"])\n",
    "                except:\n",
    "                    print (\"no column to merge\")\n",
    "            \n",
    "            grid_gdf = grid_gdf.sort_values(by=[\"CS-\"+ datestring], ascending=False)\n",
    "            grid_gdf = grid_gdf.drop_duplicates(subset=['centroid'], keep='first')\n",
    "            \n",
    "        except:\n",
    "            print (\"error with file \" + str(file))\n",
    "            unmerged_files.append(file)\n",
    "        # print (grid_gdf.columns)\n",
    "        # for duplicate centroid rows we keep the row with the higher CS value\n",
    "        print (\"duplicates removed \" + str(grid_gdf.shape))\n",
    "        dates_list.append(year + \"-\" + month)\n",
    "        filenum += 1\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through each folder and creates a dictionary with file name and column names\n",
    "# there is also a list created with just the file names for use later\n",
    "# It adds each of the files with more metadata to the large_files list\n",
    "\n",
    "large_files = []\n",
    "\n",
    "# Central America files\n",
    "cam_dict = {}\n",
    "cam_files = []\n",
    "for file in os.listdir(\"./data/ALL_HFIC/Central America and the Caribbean\"):\n",
    "    if file.endswith(\".shp\"):\n",
    "        cam_files.append(\"./data/ALL_HFIC/Central America and the Caribbean/\" + file)\n",
    "for file in cam_files:\n",
    "    if file.endswith(\".shp\"):\n",
    "        tempgdf = gpd.read_file(file)\n",
    "        cam_dict[file] = tempgdf.columns\n",
    "        if \"ADMIN1\" in tempgdf.columns:\n",
    "            large_files.append(file)\n",
    "\n",
    "# Central Asia files\n",
    "cas_dict = {}\n",
    "cas_files = []\n",
    "for file in os.listdir(\"./data/ALL_HFIC/Central Asia\"):\n",
    "    if file.endswith(\".shp\"):\n",
    "        cas_files.append(\"./data/ALL_HFIC/Central Asia/\" + file)\n",
    "for file in cas_files:\n",
    "    tempgdf = gpd.read_file(file)\n",
    "    cas_dict[file] = tempgdf.columns\n",
    "    if \"ADMIN1\" in tempgdf.columns:\n",
    "        large_files.append(file)\n",
    "\n",
    "# East Africa files\n",
    "ea_dict = {}\n",
    "ea_files = []\n",
    "for file in os.listdir(\"./data/ALL_HFIC/East Africa\"):\n",
    "    if file.endswith(\".shp\"):\n",
    "        ea_files.append(\"./data/ALL_HFIC/East Africa/\" + file)\n",
    "for file in ea_files:\n",
    "    tempgdf = gpd.read_file(file)\n",
    "    ea_dict[file] = tempgdf.columns\n",
    "    if \"ADMIN1\" in tempgdf.columns:\n",
    "        large_files.append(file)\n",
    "\n",
    "# West Africa files\n",
    "wa_dict = {}\n",
    "wa_files = []\n",
    "for file in os.listdir(\"./data/ALL_HFIC/West Africa\"):\n",
    "    if file.endswith(\".shp\"):\n",
    "        wa_files.append(\"./data/ALL_HFIC/West Africa/\" + file)\n",
    "for file in wa_files:\n",
    "    tempgdf = gpd.read_file(file)\n",
    "    wa_dict[file] = tempgdf.columns\n",
    "    if \"ADMIN1\" in tempgdf.columns:\n",
    "        large_files.append(file)\n",
    "\n",
    "# South Africa files\n",
    "sa_dict = {}\n",
    "sa_files = []\n",
    "for file in os.listdir(\"./data/ALL_HFIC/Southern Africa\"):\n",
    "    if file.endswith(\".shp\"):\n",
    "        sa_files.append(\"./data/ALL_HFIC/Southern Africa/\" + file)\n",
    "for file in sa_files:\n",
    "    tempgdf = gpd.read_file(file)\n",
    "    sa_dict[file] = tempgdf.columns\n",
    "    if \"ADMIN1\" in tempgdf.columns:\n",
    "        large_files.append(file)\n",
    "\n",
    "all_files = cam_files + cas_files + ea_files + wa_files + sa_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateslist = []\n",
    "for file in all_files:\n",
    "    month = file[-9:-7]\n",
    "    year = file[-13:-9]\n",
    "    dateslist.append(year + \"-\" + month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script below can be used to generate a list of URLs that link straight to the files on the fewsnet server\n",
    "# Use this if you do not have the files on your machine and do not want to download them\n",
    "url_list = []\n",
    "for file in ea_files:\n",
    "    if file.endswith(\".shp\"):\n",
    "        beginning = \"https://fdw.fews.net/api/ipcpackage/?country_group=\"\n",
    "        code = \"902\"\n",
    "        middle = \"&collection_date=\"\n",
    "        date = file[-13:-9] + \"-\" + file[-9:-7] + \"-\" + \"01\"\n",
    "        url_list.append(beginning + code + middle + date)\n",
    "for file in wa_files:\n",
    "    if file.endswith(\".shp\"):\n",
    "        beginning = \"https://fdw.fews.net/api/ipcpackage/?country_group=\"\n",
    "        code = \"901\"\n",
    "        middle = \"&collection_date=\"\n",
    "        date = file[-13:-9] + \"-\" + file[-9:-7] + \"-\" + \"01\"\n",
    "        url_list.append(beginning + code + middle + date)\n",
    "for file in sa_files:\n",
    "    if file.endswith(\".shp\"):\n",
    "        beginning = \"https://fdw.fews.net/api/ipcpackage/?country_group=\"\n",
    "        code = \"903\"\n",
    "        middle = \"&collection_date=\"\n",
    "        date = file[-13:-9] + \"-\" + file[-9:-7] + \"-\" + \"01\"\n",
    "        url_list.append(beginning + code + middle + date)\n",
    "for file in cam_files:\n",
    "    if file.endswith(\".shp\"):\n",
    "        beginning = \"https://fdw.fews.net/api/ipcpackage/?country_group=\"\n",
    "        code = \"904\"\n",
    "        middle = \"&collection_date=\"\n",
    "        date = file[-13:-9] + \"-\" + file[-9:-7] + \"-\" + \"01\"\n",
    "        url_list.append(beginning + code + middle + date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes one giant geodataframe with all files' data in one place\n",
    "# we can use this to get bounds for our grid\n",
    "all_full = gpd.GeoDataFrame()\n",
    "# dateslist = []\n",
    "error_files = []\n",
    "for file in all_files:\n",
    "    try:\n",
    "        print (file)\n",
    "        tempgdf = gpd.read_file(file)\n",
    "        tempgdf = tempgdf.to_crs(epsg=4326)\n",
    "        # add a column named year with the value filename[3:7]\n",
    "        # tempgdf[\"year\"] = url[-10:-6]\n",
    "        # # last character of file\n",
    "        # tempgdf[\"month\"] = url[-5:-3]\n",
    "        # dateslist.append(url[-10:-6]+'-'+url[-5:-3])\n",
    "        # add tempgdf to ea_full\n",
    "        all_full = all_full.append(tempgdf)\n",
    "    except:\n",
    "        print (\"error reading \" + file)\n",
    "        error_files.append(file)\n",
    "\n",
    "fewsnet_template_grid = make_grid(all_full.total_bounds, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/509870977.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  grid_template[\"centroid\"] = grid_template.centroid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-90.84149 14.83132, -90.74149 14.831...</td>\n",
       "      <td>POINT (-90.79149 14.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((-90.44149 14.93132, -90.34149 14.931...</td>\n",
       "      <td>POINT (-90.39149 14.98132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((-73.34149 18.43132, -73.24149 18.431...</td>\n",
       "      <td>POINT (-73.29149 18.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((-91.74149 15.83132, -91.64149 15.831...</td>\n",
       "      <td>POINT (-91.69149 15.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((-89.74149 14.23132, -89.64149 14.231...</td>\n",
       "      <td>POINT (-89.69149 14.28132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152039</th>\n",
       "      <td>POLYGON ((54.15851 12.43132, 54.25851 12.43132...</td>\n",
       "      <td>POINT (54.20851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152040</th>\n",
       "      <td>POLYGON ((54.15851 12.53132, 54.25851 12.53132...</td>\n",
       "      <td>POINT (54.20851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152041</th>\n",
       "      <td>POLYGON ((54.25851 12.43132, 54.35851 12.43132...</td>\n",
       "      <td>POINT (54.30851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152042</th>\n",
       "      <td>POLYGON ((54.25851 12.53132, 54.35851 12.53132...</td>\n",
       "      <td>POINT (54.30851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152043</th>\n",
       "      <td>POLYGON ((54.35851 12.43132, 54.45851 12.43132...</td>\n",
       "      <td>POINT (54.40851 12.48132)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 geometry  \\\n",
       "0       POLYGON ((-90.84149 14.83132, -90.74149 14.831...   \n",
       "1       POLYGON ((-90.44149 14.93132, -90.34149 14.931...   \n",
       "2       POLYGON ((-73.34149 18.43132, -73.24149 18.431...   \n",
       "3       POLYGON ((-91.74149 15.83132, -91.64149 15.831...   \n",
       "4       POLYGON ((-89.74149 14.23132, -89.64149 14.231...   \n",
       "...                                                   ...   \n",
       "152039  POLYGON ((54.15851 12.43132, 54.25851 12.43132...   \n",
       "152040  POLYGON ((54.15851 12.53132, 54.25851 12.53132...   \n",
       "152041  POLYGON ((54.25851 12.43132, 54.35851 12.43132...   \n",
       "152042  POLYGON ((54.25851 12.53132, 54.35851 12.53132...   \n",
       "152043  POLYGON ((54.35851 12.43132, 54.45851 12.43132...   \n",
       "\n",
       "                          centroid  \n",
       "0       POINT (-90.79149 14.88132)  \n",
       "1       POINT (-90.39149 14.98132)  \n",
       "2       POINT (-73.29149 18.48132)  \n",
       "3       POINT (-91.69149 15.88132)  \n",
       "4       POINT (-89.69149 14.28132)  \n",
       "...                            ...  \n",
       "152039   POINT (54.20851 12.48132)  \n",
       "152040   POINT (54.20851 12.58132)  \n",
       "152041   POINT (54.30851 12.48132)  \n",
       "152042   POINT (54.30851 12.58132)  \n",
       "152043   POINT (54.40851 12.48132)  \n",
       "\n",
       "[152044 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates the grid template to be used in join\n",
    "grid_template = gpd.read_file(\"./data/all_fewsnet_template_grid.geojson\")\n",
    "grid_template.set_geometry(\"geometry\", inplace=True)\n",
    "grid_template = grid_template.to_crs(epsg=4326)\n",
    "grid_template[\"centroid\"] = grid_template.centroid\n",
    "grid_template.set_geometry(\"centroid\", inplace=True)\n",
    "grid_template = grid_template.to_crs(epsg=4326)\n",
    "grid_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining file 1 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201007_CS.shp\n",
      "CS-2010-07\n",
      "with duplicates dataframe is (4575124, 28)\n",
      "duplicates removed (152044, 27)\n",
      "joining file 2 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201107_CS.shp\n",
      "CS-2011-07\n",
      "with duplicates dataframe is (491201, 43)\n",
      "duplicates removed (152044, 42)\n",
      "joining file 3 ./data/ALL_HFIC/Central America and the Caribbean/LAC_200910_CS.shp\n",
      "CS-2009-10\n",
      "with duplicates dataframe is (466932, 58)\n",
      "duplicates removed (152044, 57)\n",
      "joining file 4 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201204_CS.shp\n",
      "CS-2012-04\n",
      "with duplicates dataframe is (573342, 74)\n",
      "duplicates removed (152044, 73)\n",
      "joining file 5 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201304_CS.shp\n",
      "CS-2013-04\n",
      "with duplicates dataframe is (534659, 90)\n",
      "duplicates removed (152044, 89)\n",
      "joining file 6 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201410_CS.shp\n",
      "CS-2014-10\n",
      "with duplicates dataframe is (152044, 106)\n",
      "duplicates removed (152044, 105)\n",
      "joining file 7 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201510_CS.shp\n",
      "CS-2015-10\n",
      "with duplicates dataframe is (152044, 108)\n",
      "duplicates removed (152044, 107)\n",
      "joining file 8 ./data/ALL_HFIC/Central America and the Caribbean/LAC_202102_CS.shp\n",
      "CS-2021-02\n",
      "with duplicates dataframe is (152044, 110)\n",
      "duplicates removed (152044, 109)\n",
      "joining file 9 ./data/ALL_HFIC/Central America and the Caribbean/LAC_202002_CS.shp\n",
      "CS-2020-02\n",
      "with duplicates dataframe is (152044, 112)\n",
      "duplicates removed (152044, 111)\n",
      "joining file 10 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201806_CS.shp\n",
      "CS-2018-06\n",
      "with duplicates dataframe is (152044, 114)\n",
      "duplicates removed (152044, 113)\n",
      "joining file 11 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201906_CS.shp\n",
      "CS-2019-06\n",
      "with duplicates dataframe is (152044, 116)\n",
      "duplicates removed (152044, 115)\n",
      "joining file 12 ./data/ALL_HFIC/Central America and the Caribbean/LAC_202010_CS.shp\n",
      "CS-2020-10\n",
      "with duplicates dataframe is (152044, 118)\n",
      "duplicates removed (152044, 117)\n",
      "joining file 13 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201310_CS.shp\n",
      "CS-2013-10\n",
      "with duplicates dataframe is (152044, 120)\n",
      "duplicates removed (152044, 119)\n",
      "joining file 14 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201210_CS.shp\n",
      "CS-2012-10\n",
      "with duplicates dataframe is (152044, 122)\n",
      "duplicates removed (152044, 121)\n",
      "joining file 15 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201802_CS.shp\n",
      "CS-2018-02\n",
      "with duplicates dataframe is (152044, 124)\n",
      "duplicates removed (152044, 123)\n",
      "joining file 16 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201902_CS.shp\n",
      "CS-2019-02\n",
      "with duplicates dataframe is (152044, 126)\n",
      "duplicates removed (152044, 125)\n",
      "joining file 17 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201910_CS.shp\n",
      "CS-2019-10\n",
      "with duplicates dataframe is (152044, 128)\n",
      "duplicates removed (152044, 127)\n",
      "joining file 18 ./data/ALL_HFIC/Central America and the Caribbean/LAC_202106_CS.shp\n",
      "CS-2021-06\n",
      "with duplicates dataframe is (152044, 130)\n",
      "duplicates removed (152044, 129)\n",
      "joining file 19 ./data/ALL_HFIC/Central America and the Caribbean/LAC_202006_CS.shp\n",
      "CS-2020-06\n",
      "with duplicates dataframe is (152044, 132)\n",
      "duplicates removed (152044, 131)\n",
      "joining file 20 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201001_CS.shp\n",
      "CS-2010-01\n",
      "with duplicates dataframe is (152044, 133)\n",
      "duplicates removed (152044, 132)\n",
      "joining file 21 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201101_CS.shp\n",
      "CS-2011-01\n",
      "with duplicates dataframe is (152044, 134)\n",
      "duplicates removed (152044, 133)\n",
      "joining file 22 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201812_CS.shp\n",
      "CS-2018-12\n",
      "with duplicates dataframe is (152044, 136)\n",
      "duplicates removed (152044, 135)\n",
      "joining file 23 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201504_CS.shp\n",
      "CS-2015-04\n",
      "with duplicates dataframe is (152044, 138)\n",
      "duplicates removed (152044, 137)\n",
      "joining file 24 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201404_CS.shp\n",
      "CS-2014-04\n",
      "with duplicates dataframe is (152044, 140)\n",
      "duplicates removed (152044, 139)\n",
      "joining file 25 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201401_CS.shp\n",
      "CS-2014-01\n",
      "with duplicates dataframe is (152044, 142)\n",
      "duplicates removed (152044, 141)\n",
      "joining file 26 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201501_CS.shp\n",
      "CS-2015-01\n",
      "with duplicates dataframe is (152044, 144)\n",
      "duplicates removed (152044, 143)\n",
      "joining file 27 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201710_CS.shp\n",
      "CS-2017-10\n",
      "with duplicates dataframe is (152044, 146)\n",
      "duplicates removed (152044, 145)\n",
      "joining file 28 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201610_CS.shp\n",
      "CS-2016-10\n",
      "with duplicates dataframe is (152044, 148)\n",
      "duplicates removed (152044, 147)\n",
      "joining file 29 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201602_CS.shp\n",
      "CS-2016-02\n",
      "with duplicates dataframe is (152044, 150)\n",
      "duplicates removed (152044, 149)\n",
      "joining file 30 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201702_CS.shp\n",
      "CS-2017-02\n",
      "with duplicates dataframe is (152044, 152)\n",
      "duplicates removed (152044, 151)\n",
      "joining file 31 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201104_CS.shp\n",
      "CS-2011-04\n",
      "with duplicates dataframe is (152044, 153)\n",
      "duplicates removed (152044, 152)\n",
      "joining file 32 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201004_CS.shp\n",
      "CS-2010-04\n",
      "with duplicates dataframe is (152044, 154)\n",
      "duplicates removed (152044, 153)\n",
      "joining file 33 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201307_CS.shp\n",
      "CS-2013-07\n",
      "with duplicates dataframe is (152044, 156)\n",
      "duplicates removed (152044, 155)\n",
      "joining file 34 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201207_CS.shp\n",
      "CS-2012-07\n",
      "with duplicates dataframe is (152044, 158)\n",
      "duplicates removed (152044, 157)\n",
      "joining file 35 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201407_CS.shp\n",
      "CS-2014-07\n",
      "with duplicates dataframe is (152044, 160)\n",
      "duplicates removed (152044, 159)\n",
      "joining file 36 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201507_CS.shp\n",
      "CS-2015-07\n",
      "with duplicates dataframe is (152044, 162)\n",
      "duplicates removed (152044, 161)\n",
      "joining file 37 ./data/ALL_HFIC/Central America and the Caribbean/CAaC_202110_CS.shp\n",
      "CS-2021-10\n",
      "with duplicates dataframe is (152044, 175)\n",
      "duplicates removed (152044, 174)\n",
      "joining file 38 ./data/ALL_HFIC/Central America and the Caribbean/LAC_200907_CS.shp\n",
      "CS-2009-07\n",
      "with duplicates dataframe is (152044, 176)\n",
      "duplicates removed (152044, 175)\n",
      "joining file 39 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201301_CS.shp\n",
      "CS-2013-01\n",
      "with duplicates dataframe is (152044, 178)\n",
      "duplicates removed (152044, 177)\n",
      "joining file 40 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201201_CS.shp\n",
      "CS-2012-01\n",
      "with duplicates dataframe is (152044, 179)\n",
      "duplicates removed (152044, 178)\n",
      "joining file 41 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201010_CS.shp\n",
      "CS-2010-10\n",
      "with duplicates dataframe is (152044, 180)\n",
      "duplicates removed (152044, 179)\n",
      "joining file 42 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201110_CS.shp\n",
      "CS-2011-10\n",
      "with duplicates dataframe is (152044, 181)\n",
      "duplicates removed (152044, 180)\n",
      "joining file 43 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201606_CS.shp\n",
      "CS-2016-06\n",
      "with duplicates dataframe is (152044, 183)\n",
      "duplicates removed (152044, 182)\n",
      "joining file 44 ./data/ALL_HFIC/Central America and the Caribbean/LAC_201706_CS.shp\n",
      "CS-2017-06\n",
      "with duplicates dataframe is (152044, 185)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 45 ./data/ALL_HFIC/Central Asia/CA_201404_CS.shp\n",
      "CS-2014-04\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 46 ./data/ALL_HFIC/Central Asia/CA_201504_CS.shp\n",
      "CS-2015-04\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 47 ./data/ALL_HFIC/Central Asia/CA_201101_CS.shp\n",
      "CS-2011-01\n",
      "with duplicates dataframe is (152044, 186)\n",
      "no column to merge\n",
      "duplicates removed (152044, 184)\n",
      "joining file 48 ./data/ALL_HFIC/Central Asia/CA_201001_CS.shp\n",
      "CS-2010-01\n",
      "with duplicates dataframe is (152044, 186)\n",
      "no column to merge\n",
      "duplicates removed (152044, 184)\n",
      "joining file 49 ./data/ALL_HFIC/Central Asia/CA_201902_CS.shp\n",
      "CS-2019-02\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 50 ./data/ALL_HFIC/Central Asia/CA_201802_CS.shp\n",
      "CS-2018-02\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 51 ./data/ALL_HFIC/Central Asia/CA_202106_CS.shp\n",
      "CS-2021-06\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 184)\n",
      "joining file 52 ./data/ALL_HFIC/Central Asia/CA_201810_CS.shp\n",
      "CS-2018-10\n",
      "with duplicates dataframe is (152044, 187)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 53 ./data/ALL_HFIC/Central Asia/CA_201910_CS.shp\n",
      "CS-2019-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 54 ./data/ALL_HFIC/Central Asia/CA_201210_CS.shp\n",
      "CS-2012-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 55 ./data/ALL_HFIC/Central Asia/CA_201310_CS.shp\n",
      "CS-2013-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 56 ./data/ALL_HFIC/Central Asia/CA_202002_CS.shp\n",
      "CS-2020-02\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 57 ./data/ALL_HFIC/Central Asia/CA_202102_CS.shp\n",
      "CS-2021-02\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 58 ./data/ALL_HFIC/Central Asia/CA_202010_CS.shp\n",
      "CS-2020-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 59 ./data/ALL_HFIC/Central Asia/CA_201906_CS.shp\n",
      "CS-2019-06\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 60 ./data/ALL_HFIC/Central Asia/CA_201806_CS.shp\n",
      "CS-2018-06\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 61 ./data/ALL_HFIC/Central Asia/CA_201510_CS.shp\n",
      "CS-2015-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 62 ./data/ALL_HFIC/Central Asia/CA_201410_CS.shp\n",
      "CS-2014-10\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 63 ./data/ALL_HFIC/Central Asia/CA_201304_CS.shp\n",
      "CS-2013-04\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 64 ./data/ALL_HFIC/Central Asia/CA_201204_CS.shp\n",
      "CS-2012-04\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 65 ./data/ALL_HFIC/Central Asia/CA_200910_CS.shp\n",
      "CS-2009-10\n",
      "with duplicates dataframe is (152044, 188)\n",
      "no column to merge\n",
      "duplicates removed (152044, 186)\n",
      "joining file 66 ./data/ALL_HFIC/Central Asia/CA_201107_CS.shp\n",
      "CS-2011-07\n",
      "with duplicates dataframe is (152044, 188)\n",
      "no column to merge\n",
      "duplicates removed (152044, 186)\n",
      "joining file 67 ./data/ALL_HFIC/Central Asia/CA_201007_CS.shp\n",
      "CS-2010-07\n",
      "with duplicates dataframe is (152044, 188)\n",
      "no column to merge\n",
      "duplicates removed (152044, 186)\n",
      "joining file 68 ./data/ALL_HFIC/Central Asia/CA_201706_CS.shp\n",
      "CS-2017-06\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 69 ./data/ALL_HFIC/Central Asia/CA_201606_CS.shp\n",
      "CS-2016-06\n",
      "with duplicates dataframe is (152044, 189)\n",
      "duplicates removed (152044, 186)\n",
      "joining file 70 ./data/ALL_HFIC/Central Asia/CA_201110_CS.shp\n",
      "CS-2011-10\n",
      "with duplicates dataframe is (152044, 188)\n",
      "no column to merge\n",
      "duplicates removed (152044, 186)\n",
      "joining file 71 ./data/ALL_HFIC/Central Asia/CA_201010_CS.shp\n",
      "CS-2010-10\n",
      "with duplicates dataframe is (152044, 188)\n",
      "no column to merge\n",
      "duplicates removed (152044, 186)\n",
      "joining file 72 ./data/ALL_HFIC/Central Asia/CA_201201_CS.shp\n",
      "CS-2012-01\n",
      "with duplicates dataframe is (152044, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 73 ./data/ALL_HFIC/Central Asia/CA_201301_CS.shp\n",
      "CS-2013-01\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 74 ./data/ALL_HFIC/Central Asia/CA_200907_CS.shp\n",
      "CS-2009-07\n",
      "with duplicates dataframe is (152044, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 75 ./data/ALL_HFIC/Central Asia/CA_201507_CS.shp\n",
      "CS-2015-07\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 76 ./data/ALL_HFIC/Central Asia/CA_201407_CS.shp\n",
      "CS-2014-07\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 77 ./data/ALL_HFIC/Central Asia/CA_201207_CS.shp\n",
      "CS-2012-07\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 78 ./data/ALL_HFIC/Central Asia/CA_201307_CS.shp\n",
      "CS-2013-07\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 79 ./data/ALL_HFIC/Central Asia/CA_201004_CS.shp\n",
      "CS-2010-04\n",
      "with duplicates dataframe is (152044, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 80 ./data/ALL_HFIC/Central Asia/CA_201104_CS.shp\n",
      "CS-2011-04\n",
      "with duplicates dataframe is (152044, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 81 ./data/ALL_HFIC/Central Asia/CA_201610_CS.shp\n",
      "CS-2016-10\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 82 ./data/ALL_HFIC/Central Asia/CA_201710_CS.shp\n",
      "CS-2017-10\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 83 ./data/ALL_HFIC/Central Asia/CA_201702_CS.shp\n",
      "CS-2017-02\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 84 ./data/ALL_HFIC/Central Asia/CA_201602_CS.shp\n",
      "CS-2016-02\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 85 ./data/ALL_HFIC/Central Asia/CA_201501_CS.shp\n",
      "CS-2015-01\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 86 ./data/ALL_HFIC/Central Asia/CA_201401_CS.shp\n",
      "CS-2014-01\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 87 ./data/ALL_HFIC/East Africa/EA_201802_CS.shp\n",
      "CS-2018-02\n",
      "with duplicates dataframe is (152191, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 88 ./data/ALL_HFIC/East Africa/EA_201902_CS.shp\n",
      "CS-2019-02\n",
      "with duplicates dataframe is (152151, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 89 ./data/ALL_HFIC/East Africa/EA_202106_CS.shp\n",
      "CS-2021-06\n",
      "with duplicates dataframe is (152044, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 90 ./data/ALL_HFIC/East Africa/EA_202006_CS.shp\n",
      "CS-2020-06\n",
      "with duplicates dataframe is (152155, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 91 ./data/ALL_HFIC/East Africa/EA_201910_CS.shp\n",
      "CS-2019-10\n",
      "with duplicates dataframe is (152079, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 92 ./data/ALL_HFIC/East Africa/EA_201810_CS.shp\n",
      "CS-2018-10\n",
      "with duplicates dataframe is (152204, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 93 ./data/ALL_HFIC/East Africa/EA_201001_CS.shp\n",
      "CS-2010-01\n",
      "with duplicates dataframe is (152120, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 94 ./data/ALL_HFIC/East Africa/EA_201101_CS.shp\n",
      "CS-2011-01\n",
      "with duplicates dataframe is (152124, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 95 ./data/ALL_HFIC/East Africa/EA_201310_CS.shp\n",
      "CS-2013-10\n",
      "with duplicates dataframe is (152151, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 96 ./data/ALL_HFIC/East Africa/EA_201210_CS.shp\n",
      "CS-2012-10\n",
      "with duplicates dataframe is (152200, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 97 ./data/ALL_HFIC/East Africa/EA_201504_CS.shp\n",
      "CS-2015-04\n",
      "with duplicates dataframe is (152075, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 98 ./data/ALL_HFIC/East Africa/EA_201404_CS.shp\n",
      "CS-2014-04\n",
      "with duplicates dataframe is (152200, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 99 ./data/ALL_HFIC/East Africa/EA_201812_CS.shp\n",
      "CS-2018-12\n",
      "with duplicates dataframe is (152204, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 100 ./data/ALL_HFIC/East Africa/EA_200910_CS.shp\n",
      "CS-2009-10\n",
      "with duplicates dataframe is (152120, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 101 ./data/ALL_HFIC/East Africa/EA_201204_CS.shp\n",
      "CS-2012-04\n",
      "with duplicates dataframe is (152138, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 102 ./data/ALL_HFIC/East Africa/EA_201304_CS.shp\n",
      "CS-2013-04\n",
      "with duplicates dataframe is (152200, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 103 ./data/ALL_HFIC/East Africa/EA_201007_CS.shp\n",
      "CS-2010-07\n",
      "with duplicates dataframe is (152120, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 104 ./data/ALL_HFIC/East Africa/EA_201107_CS.shp\n",
      "CS-2011-07\n",
      "with duplicates dataframe is (152200, 189)\n",
      "no column to merge\n",
      "duplicates removed (152044, 187)\n",
      "joining file 105 ./data/ALL_HFIC/East Africa/EA_202102_CS.shp\n",
      "CS-2021-02\n",
      "with duplicates dataframe is (152200, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 106 ./data/ALL_HFIC/East Africa/EA_202002_CS.shp\n",
      "CS-2020-02\n",
      "with duplicates dataframe is (152204, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 107 ./data/ALL_HFIC/East Africa/EA_202010_CS.shp\n",
      "CS-2020-10\n",
      "with duplicates dataframe is (152204, 190)\n",
      "duplicates removed (152044, 187)\n",
      "joining file 108 ./data/ALL_HFIC/East Africa/EA_202110_CS.shp\n",
      "CS-2021-10\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 109 ./data/ALL_HFIC/East Africa/EA_201806_CS.shp\n",
      "CS-2018-06\n",
      "with duplicates dataframe is (152195, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 110 ./data/ALL_HFIC/East Africa/EA_201906_CS.shp\n",
      "CS-2019-06\n",
      "with duplicates dataframe is (152155, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 111 ./data/ALL_HFIC/East Africa/EA_201410_CS.shp\n",
      "CS-2014-10\n",
      "with duplicates dataframe is (152169, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 112 ./data/ALL_HFIC/East Africa/EA_201510_CS.shp\n",
      "CS-2015-10\n",
      "with duplicates dataframe is (152124, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 113 ./data/ALL_HFIC/East Africa/EA_201407_CS.shp\n",
      "CS-2014-07\n",
      "with duplicates dataframe is (152200, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 114 ./data/ALL_HFIC/East Africa/EA_201507_CS.shp\n",
      "CS-2015-07\n",
      "with duplicates dataframe is (152075, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 115 ./data/ALL_HFIC/East Africa/EA_201010_CS.shp\n",
      "CS-2010-10\n",
      "with duplicates dataframe is (152124, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 116 ./data/ALL_HFIC/East Africa/EA_201110_CS.shp\n",
      "CS-2011-10\n",
      "with duplicates dataframe is (152120, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 117 ./data/ALL_HFIC/East Africa/EA_201606_CS.shp\n",
      "CS-2016-06\n",
      "with duplicates dataframe is (152200, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 118 ./data/ALL_HFIC/East Africa/EA_201706_CS.shp\n",
      "CS-2017-06\n",
      "with duplicates dataframe is (152084, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 119 ./data/ALL_HFIC/East Africa/EA_200907_CS.shp\n",
      "CS-2009-07\n",
      "with duplicates dataframe is (152120, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 120 ./data/ALL_HFIC/East Africa/EA_201301_CS.shp\n",
      "CS-2013-01\n",
      "with duplicates dataframe is (152200, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 121 ./data/ALL_HFIC/East Africa/EA_201201_CS.shp\n",
      "CS-2012-01\n",
      "with duplicates dataframe is (152138, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 122 ./data/ALL_HFIC/East Africa/EA_201710_CS.shp\n",
      "CS-2017-10\n",
      "with duplicates dataframe is (152151, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 123 ./data/ALL_HFIC/East Africa/EA_201610_CS.shp\n",
      "CS-2016-10\n",
      "with duplicates dataframe is (152075, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 124 ./data/ALL_HFIC/East Africa/EA_201602_CS.shp\n",
      "CS-2016-02\n",
      "with duplicates dataframe is (152075, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 125 ./data/ALL_HFIC/East Africa/EA_201702_CS.shp\n",
      "CS-2017-02\n",
      "with duplicates dataframe is (152084, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 126 ./data/ALL_HFIC/East Africa/EA_201401_CS.shp\n",
      "CS-2014-01\n",
      "with duplicates dataframe is (152200, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 127 ./data/ALL_HFIC/East Africa/EA_201501_CS.shp\n",
      "CS-2015-01\n",
      "with duplicates dataframe is (152124, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 128 ./data/ALL_HFIC/East Africa/EA_201307_CS.shp\n",
      "CS-2013-07\n",
      "with duplicates dataframe is (152075, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 129 ./data/ALL_HFIC/East Africa/EA_201207_CS.shp\n",
      "CS-2012-07\n",
      "with duplicates dataframe is (152204, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 130 ./data/ALL_HFIC/East Africa/EA_201104_CS.shp\n",
      "CS-2011-04\n",
      "with duplicates dataframe is (152124, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 131 ./data/ALL_HFIC/East Africa/EA_201004_CS.shp\n",
      "CS-2010-04\n",
      "with duplicates dataframe is (152120, 200)\n",
      "no column to merge\n",
      "duplicates removed (152044, 198)\n",
      "joining file 132 ./data/ALL_HFIC/West Africa/WA_201401_CS.shp\n",
      "CS-2014-01\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 133 ./data/ALL_HFIC/West Africa/WA_201501_CS.shp\n",
      "CS-2015-01\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 134 ./data/ALL_HFIC/West Africa/WA_201710_CS.shp\n",
      "CS-2017-10\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 135 ./data/ALL_HFIC/West Africa/WA_201610_CS.shp\n",
      "CS-2016-10\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 136 ./data/ALL_HFIC/West Africa/WA_201602_CS.shp\n",
      "CS-2016-02\n",
      "with duplicates dataframe is (152044, 201)\n",
      "duplicates removed (152044, 198)\n",
      "joining file 137 ./data/ALL_HFIC/West Africa/WA_201702_CS.shp\n",
      "CS-2017-02\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 138 ./data/ALL_HFIC/West Africa/WA_201104_CS.shp\n",
      "CS-2011-04\n",
      "with duplicates dataframe is (152044, 201)\n",
      "no column to merge\n",
      "duplicates removed (152044, 199)\n",
      "joining file 139 ./data/ALL_HFIC/West Africa/WA_201004_CS.shp\n",
      "CS-2010-04\n",
      "with duplicates dataframe is (152044, 201)\n",
      "no column to merge\n",
      "duplicates removed (152044, 199)\n",
      "joining file 140 ./data/ALL_HFIC/West Africa/WA_201307_CS.shp\n",
      "CS-2013-07\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 141 ./data/ALL_HFIC/West Africa/WA_201207_CS.shp\n",
      "CS-2012-07\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 142 ./data/ALL_HFIC/West Africa/WA_201407_CS.shp\n",
      "CS-2014-07\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 143 ./data/ALL_HFIC/West Africa/WA_201507_CS.shp\n",
      "CS-2015-07\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 144 ./data/ALL_HFIC/West Africa/WA_201301_CS.shp\n",
      "CS-2013-01\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 145 ./data/ALL_HFIC/West Africa/WA_201201_CS.shp\n",
      "CS-2012-01\n",
      "with duplicates dataframe is (152044, 201)\n",
      "no column to merge\n",
      "duplicates removed (152044, 199)\n",
      "joining file 146 ./data/ALL_HFIC/West Africa/WA_200907_CS.shp\n",
      "CS-2009-07\n",
      "with duplicates dataframe is (152044, 201)\n",
      "no column to merge\n",
      "duplicates removed (152044, 199)\n",
      "joining file 147 ./data/ALL_HFIC/West Africa/WA_201606_CS.shp\n",
      "CS-2016-06\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 148 ./data/ALL_HFIC/West Africa/WA_201706_CS.shp\n",
      "CS-2017-06\n",
      "with duplicates dataframe is (152044, 202)\n",
      "duplicates removed (152044, 199)\n",
      "joining file 149 ./data/ALL_HFIC/West Africa/WA_201010_CS.shp\n",
      "CS-2010-10\n",
      "with duplicates dataframe is (152044, 202)\n",
      "no column to merge\n",
      "duplicates removed (152044, 200)\n",
      "joining file 150 ./data/ALL_HFIC/West Africa/WA_201110_CS.shp\n",
      "CS-2011-10\n",
      "with duplicates dataframe is (152044, 203)\n",
      "no column to merge\n",
      "duplicates removed (152044, 201)\n",
      "joining file 151 ./data/ALL_HFIC/West Africa/WA_201007_CS.shp\n",
      "CS-2010-07\n",
      "with duplicates dataframe is (152044, 203)\n",
      "no column to merge\n",
      "duplicates removed (152044, 201)\n",
      "joining file 152 ./data/ALL_HFIC/West Africa/WA_201107_CS.shp\n",
      "CS-2011-07\n",
      "with duplicates dataframe is (152044, 203)\n",
      "no column to merge\n",
      "duplicates removed (152044, 201)\n",
      "joining file 153 ./data/ALL_HFIC/West Africa/WA_201204_CS.shp\n",
      "CS-2012-04\n",
      "with duplicates dataframe is (152044, 204)\n",
      "duplicates removed (152044, 201)\n",
      "joining file 154 ./data/ALL_HFIC/West Africa/WA_201304_CS.shp\n",
      "CS-2013-04\n",
      "with duplicates dataframe is (152044, 204)\n",
      "duplicates removed (152044, 201)\n",
      "joining file 155 ./data/ALL_HFIC/West Africa/WA_200910_CS.shp\n",
      "CS-2009-10\n",
      "with duplicates dataframe is (152044, 204)\n",
      "no column to merge\n",
      "duplicates removed (152044, 202)\n",
      "joining file 156 ./data/ALL_HFIC/West Africa/WA_201410_CS.shp\n",
      "CS-2014-10\n",
      "with duplicates dataframe is (152044, 205)\n",
      "duplicates removed (152044, 202)\n",
      "joining file 157 ./data/ALL_HFIC/West Africa/WA_201510_CS.shp\n",
      "CS-2015-10\n",
      "with duplicates dataframe is (152044, 205)\n",
      "duplicates removed (152044, 202)\n",
      "joining file 158 ./data/ALL_HFIC/West Africa/WA_202102_CS.shp\n",
      "CS-2021-02\n",
      "with duplicates dataframe is (152044, 205)\n",
      "duplicates removed (152044, 202)\n",
      "joining file 159 ./data/ALL_HFIC/West Africa/WA_202002_CS.shp\n",
      "CS-2020-02\n",
      "with duplicates dataframe is (152044, 205)\n",
      "duplicates removed (152044, 202)\n",
      "joining file 160 ./data/ALL_HFIC/West Africa/WA_202010_CS.shp\n",
      "CS-2020-10\n",
      "with duplicates dataframe is (152044, 205)\n",
      "duplicates removed (152044, 202)\n",
      "joining file 161 ./data/ALL_HFIC/West Africa/WA_202110_CS.shp\n",
      "CS-2021-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 162 ./data/ALL_HFIC/West Africa/WA_201806_CS.shp\n",
      "CS-2018-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 163 ./data/ALL_HFIC/West Africa/WA_201906_CS.shp\n",
      "CS-2019-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 164 ./data/ALL_HFIC/West Africa/WA_201310_CS.shp\n",
      "CS-2013-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 165 ./data/ALL_HFIC/West Africa/WA_201210_CS.shp\n",
      "CS-2012-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 166 ./data/ALL_HFIC/West Africa/WA_201001_CS.shp\n",
      "CS-2010-01\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 167 ./data/ALL_HFIC/West Africa/WA_201101_CS.shp\n",
      "CS-2011-01\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 168 ./data/ALL_HFIC/West Africa/WA_201802_CS.shp\n",
      "CS-2018-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 169 ./data/ALL_HFIC/West Africa/WA_201902_CS.shp\n",
      "CS-2019-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 170 ./data/ALL_HFIC/West Africa/WA_202106_CS.shp\n",
      "CS-2021-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 171 ./data/ALL_HFIC/West Africa/WA_202006_CS.shp\n",
      "CS-2020-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 172 ./data/ALL_HFIC/West Africa/WA_201910_CS.shp\n",
      "CS-2019-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 173 ./data/ALL_HFIC/West Africa/WA_201810_CS.shp\n",
      "CS-2018-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 174 ./data/ALL_HFIC/West Africa/WA_201812_CS.shp\n",
      "CS-2018-12\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 175 ./data/ALL_HFIC/West Africa/WA_201504_CS.shp\n",
      "CS-2015-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 176 ./data/ALL_HFIC/West Africa/WA_201404_CS.shp\n",
      "CS-2014-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 177 ./data/ALL_HFIC/Southern Africa/SA_201407_CS.shp\n",
      "CS-2014-07\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 178 ./data/ALL_HFIC/Southern Africa/SA_201507_CS.shp\n",
      "CS-2015-07\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 179 ./data/ALL_HFIC/Southern Africa/SA_201010_CS.shp\n",
      "CS-2010-10\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 180 ./data/ALL_HFIC/Southern Africa/SA_201110_CS.shp\n",
      "CS-2011-10\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 181 ./data/ALL_HFIC/Southern Africa/SA_201606_CS.shp\n",
      "CS-2016-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 182 ./data/ALL_HFIC/Southern Africa/SA_201706_CS.shp\n",
      "CS-2017-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 183 ./data/ALL_HFIC/Southern Africa/SA_200907_CS.shp\n",
      "CS-2009-07\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 184 ./data/ALL_HFIC/Southern Africa/SA_201301_CS.shp\n",
      "CS-2013-01\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 185 ./data/ALL_HFIC/Southern Africa/SA_201201_CS.shp\n",
      "CS-2012-01\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 186 ./data/ALL_HFIC/Southern Africa/SA_201602_CS.shp\n",
      "CS-2016-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 187 ./data/ALL_HFIC/Southern Africa/SA_201702_CS.shp\n",
      "CS-2017-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 188 ./data/ALL_HFIC/Southern Africa/SA_201710_CS.shp\n",
      "CS-2017-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 189 ./data/ALL_HFIC/Southern Africa/SA_201610_CS.shp\n",
      "CS-2016-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 190 ./data/ALL_HFIC/Southern Africa/SA_201401_CS.shp\n",
      "CS-2014-01\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 191 ./data/ALL_HFIC/Southern Africa/SA_201501_CS.shp\n",
      "CS-2015-01\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 192 ./data/ALL_HFIC/Southern Africa/SA_201307_CS.shp\n",
      "CS-2013-07\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 193 ./data/ALL_HFIC/Southern Africa/SA_201207_CS.shp\n",
      "CS-2012-07\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 194 ./data/ALL_HFIC/Southern Africa/SA_201104_CS.shp\n",
      "CS-2011-04\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 195 ./data/ALL_HFIC/Southern Africa/SA_201004_CS.shp\n",
      "CS-2010-04\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 196 ./data/ALL_HFIC/Southern Africa/SA_201910_CS.shp\n",
      "CS-2019-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 197 ./data/ALL_HFIC/Southern Africa/SA_201810_CS.shp\n",
      "CS-2018-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 198 ./data/ALL_HFIC/Southern Africa/SA_202106_CS.shp\n",
      "CS-2021-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 199 ./data/ALL_HFIC/Southern Africa/SA_202006_CS.shp\n",
      "CS-2020-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 200 ./data/ALL_HFIC/Southern Africa/SA_201802_CS.shp\n",
      "CS-2018-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 201 ./data/ALL_HFIC/Southern Africa/SA_201902_CS.shp\n",
      "CS-2019-02\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 202 ./data/ALL_HFIC/Southern Africa/SA_201001_CS.shp\n",
      "CS-2010-01\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 203 ./data/ALL_HFIC/Southern Africa/SA_201101_CS.shp\n",
      "CS-2011-01\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 204 ./data/ALL_HFIC/Southern Africa/SA_201310_CS.shp\n",
      "CS-2013-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 205 ./data/ALL_HFIC/Southern Africa/SA_201210_CS.shp\n",
      "CS-2012-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 206 ./data/ALL_HFIC/Southern Africa/SA_201504_CS.shp\n",
      "CS-2015-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 207 ./data/ALL_HFIC/Southern Africa/SA_201404_CS.shp\n",
      "CS-2014-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 208 ./data/ALL_HFIC/Southern Africa/SA_201812_CS.shp\n",
      "CS-2018-12\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 209 ./data/ALL_HFIC/Southern Africa/SA_200910_CS.shp\n",
      "CS-2009-10\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 210 ./data/ALL_HFIC/Southern Africa/SA_201204_CS.shp\n",
      "CS-2012-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 211 ./data/ALL_HFIC/Southern Africa/SA_201304_CS.shp\n",
      "CS-2013-04\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 212 ./data/ALL_HFIC/Southern Africa/SA_201007_CS.shp\n",
      "CS-2010-07\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 213 ./data/ALL_HFIC/Southern Africa/SA_201107_CS.shp\n",
      "CS-2011-07\n",
      "with duplicates dataframe is (152044, 215)\n",
      "no column to merge\n",
      "duplicates removed (152044, 213)\n",
      "joining file 214 ./data/ALL_HFIC/Southern Africa/SA_201806_CS.shp\n",
      "CS-2018-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 215 ./data/ALL_HFIC/Southern Africa/SA_201906_CS.shp\n",
      "CS-2019-06\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 216 ./data/ALL_HFIC/Southern Africa/SA_202010_CS.shp\n",
      "CS-2020-10\n",
      "with duplicates dataframe is (152044, 216)\n",
      "duplicates removed (152044, 213)\n",
      "joining file 217 ./data/ALL_HFIC/Southern Africa/SA_202110_CS.shp\n",
      "CS-2021-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/geodataframe.py:1499: FutureWarning: Passing 'suffixes' which cause duplicate columns {'unit_name-2021-10_left', 'ADMIN0-2021-10_left', 'ADMIN3-2021-10_left', 'LZCODE-2021-10_left', 'ADMIN2-2021-10_left', 'report_mon-2021-10_left', 'cov_end-2021-10_left', 'ADMIN1-2021-10_left', 'country-2021-10_left', 'LZNAME-2021-10_left', 'cov_start-2021-10_left'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplicates dataframe is (152044, 227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed (152044, 224)\n",
      "joining file 218 ./data/ALL_HFIC/Southern Africa/SA_202102_CS.shp\n",
      "CS-2021-02\n",
      "with duplicates dataframe is (152044, 227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed (152044, 224)\n",
      "joining file 219 ./data/ALL_HFIC/Southern Africa/SA_202002_CS.shp\n",
      "CS-2020-02\n",
      "with duplicates dataframe is (152044, 227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed (152044, 224)\n",
      "joining file 220 ./data/ALL_HFIC/Southern Africa/SA_201410_CS.shp\n",
      "CS-2014-10\n",
      "with duplicates dataframe is (152044, 227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed (152044, 224)\n",
      "joining file 221 ./data/ALL_HFIC/Southern Africa/SA_201510_CS.shp\n",
      "CS-2015-10\n",
      "with duplicates dataframe is (152044, 227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"CS-\"+datestring+\"_left\"].fillna(grid_gdf[\"CS-\"+datestring+\"_right\"], inplace=True)\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_41960/2115360759.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  grid_gdf[\"HA0-\"+datestring+\"_left\"] = grid_gdf[\"HA0-\"+datestring+\"_left\"].fillna(grid_gdf[\"HA0-\"+datestring+\"_right\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates removed (152044, 224)\n"
     ]
    }
   ],
   "source": [
    "# Joining the files to the grid\n",
    "all_fewsnet_grid = join_to_grid(grid_template, all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a backup of thd df in case I do something stupid\n",
    "all_fewsnet_grid_proof = all_fewsnet_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the troubled column names and join\n",
    "troubled_columns = ['CS200910_P-2009-10', 'CS201010_P-2010-10', 'CS201110_P-2011-10', 'CS201201_P-2012-01']\n",
    "\n",
    "all_fewsnet_grid[\"CS-2009-10\"].fillna(all_fewsnet_grid['CS200910_P-2009-10'] , inplace=True)\n",
    "all_fewsnet_grid[\"CS-2010-10\"].fillna(all_fewsnet_grid['CS201010_P-2010-10'] , inplace=True)\n",
    "all_fewsnet_grid[\"CS-2011-10\"].fillna(all_fewsnet_grid['CS201110_P-2011-10'] , inplace=True)\n",
    "all_fewsnet_grid[\"CS-2012-01\"].fillna(all_fewsnet_grid['CS201201_P-2012-01'] , inplace=True)\n",
    "\n",
    "all_fewsnet_grid = all_fewsnet_grid.drop(columns=troubled_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152044, 220)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting rid of rows that are all nan's. shouldn't be any with the template\n",
    "all_fewsnet_grid = all_fewsnet_grid.dropna(axis=0, how='all', subset=all_fewsnet_grid.iloc[:,3:224].columns)\n",
    "all_fewsnet_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cov_start-2021-10_left', 'cov_end-2021-10_left',\n",
      "       'report_mon-2021-10_left', 'country-2021-10_left',\n",
      "       'unit_name-2021-10_left', 'ADMIN0-2021-10_left', 'ADMIN1-2021-10_left',\n",
      "       'ADMIN2-2021-10_left', 'ADMIN3-2021-10_left', 'LZCODE-2021-10_left',\n",
      "       'LZNAME-2021-10_left', 'cov_start-2021-10_right',\n",
      "       'cov_end-2021-10_right', 'report_mon-2021-10_right',\n",
      "       'country-2021-10_right', 'unit_name-2021-10_right',\n",
      "       'ADMIN0-2021-10_right', 'ADMIN1-2021-10_right', 'ADMIN2-2021-10_right',\n",
      "       'ADMIN3-2021-10_right', 'LZCODE-2021-10_right', 'LZNAME-2021-10_right'],\n",
      "      dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# taking care of duplicate column names\n",
    "class renamer():\n",
    "    def __init__(self):\n",
    "        self.d = dict()\n",
    "    def __call__(self, x):\n",
    "        if x not in self.d:\n",
    "            self.d[x] = 0\n",
    "            return x\n",
    "        else:\n",
    "            self.d[x] += 1\n",
    "            return \"%s_%d\" % (x, self.d[x])\n",
    "            df.rename(columns=renamer())\n",
    "print (all_fewsnet_grid.columns[all_fewsnet_grid.columns.duplicated()])\n",
    "all_fewsnet_grid = all_fewsnet_grid.rename(columns=renamer())\n",
    "print (all_fewsnet_grid.columns[all_fewsnet_grid.columns.duplicated()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid df written to file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m all_fewsnet_centroid \u001b[39m=\u001b[39m all_fewsnet_centroid\u001b[39m.\u001b[39mset_geometry(\u001b[39m'\u001b[39m\u001b[39mcentroid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m all_fewsnet_centroid\u001b[39m.\u001b[39mset_crs(epsg\u001b[39m=\u001b[39m\u001b[39m4326\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m all_fewsnet_centroid\u001b[39m.\u001b[39;49mto_file(\u001b[39m\"\u001b[39;49m\u001b[39m./data/all_fewsnet_centroid.geojson\u001b[39;49m\u001b[39m\"\u001b[39;49m, driver\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGeoJSON\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcentroid df written to file\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/geodataframe.py:1216\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \n\u001b[1;32m   1135\u001b[0m \u001b[39mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39m>>> gdf.to_file('dataframe.shp', mode=\"a\")  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile\u001b[39;00m \u001b[39mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1216\u001b[0m _to_file(\u001b[39mself\u001b[39;49m, filename, driver, schema, index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/io/file.py:525\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    519\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mColumn names longer than 10 characters will be truncated when saved to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mESRI Shapefile.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiona\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    526\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyogrio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    527\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/io/file.py:555\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[0;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m     crs_wkt \u001b[39m=\u001b[39m crs\u001b[39m.\u001b[39mto_wkt(\u001b[39m\"\u001b[39m\u001b[39mWKT1_GDAL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m \u001b[39mwith\u001b[39;00m fiona\u001b[39m.\u001b[39mopen(\n\u001b[1;32m    553\u001b[0m     filename, mode\u001b[39m=\u001b[39mmode, driver\u001b[39m=\u001b[39mdriver, crs_wkt\u001b[39m=\u001b[39mcrs_wkt, schema\u001b[39m=\u001b[39mschema, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    554\u001b[0m ) \u001b[39mas\u001b[39;00m colxn:\n\u001b[0;32m--> 555\u001b[0m     colxn\u001b[39m.\u001b[39;49mwriterecords(df\u001b[39m.\u001b[39;49miterfeatures())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/fiona/collection.py:361\u001b[0m, in \u001b[0;36mCollection.writerecords\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    360\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcollection not open for writing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 361\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mwriterecs(records, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_len \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mget_length()\n\u001b[1;32m    363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1291\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.writerecs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:361\u001b[0m, in \u001b[0;36mfiona.ogrext.OGRFeatureBuilder.build\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Writing to files\n",
    "all_fewsnet_grid_write = all_fewsnet_grid.drop(columns=['centroid'])\n",
    "all_fewsnet_grid_write = all_fewsnet_grid_write.set_geometry('geometry')\n",
    "all_fewsnet_grid_write.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_grid_write.to_file(\"./data/all_fewsnet_grid.geojson\", driver='GeoJSON')\n",
    "print(\"grid df written to file\")\n",
    "\n",
    "all_fewsnet_centroid = all_fewsnet_grid.drop(columns=['geometry'])\n",
    "all_fewsnet_centroid = all_fewsnet_centroid.set_geometry('centroid')\n",
    "all_fewsnet_centroid.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_centroid.to_file(\"./data/all_fewsnet_centroid.geojson\", driver='GeoJSON')\n",
    "print(\"centroid df written to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADMIN0-2009-10', 'ADMIN0-2011-07', 'ADMIN0-2012-04', 'ADMIN0-2013-04', 'ADMIN0-2014-10', 'ADMIN0-2021-10_left', 'ADMIN0-2021-10_left_1', 'ADMIN0-2021-10_right', 'ADMIN0-2021-10_right_1', 'ADMIN0_lef-2010-07', 'ADMIN0_rig-2010-07', 'ADMIN1-2009-10', 'ADMIN1-2011-07', 'ADMIN1-2012-04', 'ADMIN1-2013-04', 'ADMIN1-2014-10', 'ADMIN1-2021-10_left', 'ADMIN1-2021-10_left_1', 'ADMIN1-2021-10_right', 'ADMIN1-2021-10_right_1', 'ADMIN1FR-2009-10', 'ADMIN1FR-2011-07', 'ADMIN1FR-2012-04', 'ADMIN1FR-2013-04', 'ADMIN1FR-2014-10', 'ADMIN1FR_l-2010-07', 'ADMIN1FR_r-2010-07', 'ADMIN1PT-2009-10', 'ADMIN1PT-2011-07', 'ADMIN1PT-2012-04', 'ADMIN1PT-2013-04', 'ADMIN1PT-2014-10', 'ADMIN1PT_l-2010-07', 'ADMIN1PT_r-2010-07', 'ADMIN1SP-2009-10', 'ADMIN1SP-2011-07', 'ADMIN1SP-2012-04', 'ADMIN1SP-2013-04', 'ADMIN1SP-2014-10', 'ADMIN1SP_l-2010-07', 'ADMIN1SP_r-2010-07', 'ADMIN1_lef-2010-07', 'ADMIN1_rig-2010-07', 'ADMIN2-2009-10', 'ADMIN2-2010-07', 'ADMIN2-2011-07', 'ADMIN2-2012-04', 'ADMIN2-2013-04', 'ADMIN2-2014-10', 'ADMIN2-2021-10_left', 'ADMIN2-2021-10_left_1', 'ADMIN2-2021-10_right', 'ADMIN2-2021-10_right_1', 'ADMIN2FR-2009-10', 'ADMIN2FR-2010-07', 'ADMIN2FR-2011-07', 'ADMIN2FR-2012-04', 'ADMIN2FR-2013-04', 'ADMIN2FR-2014-10', 'ADMIN2PT-2009-10', 'ADMIN2PT-2010-07', 'ADMIN2PT-2011-07', 'ADMIN2PT-2012-04', 'ADMIN2PT-2013-04', 'ADMIN2PT-2014-10', 'ADMIN2SP-2009-10', 'ADMIN2SP-2010-07', 'ADMIN2SP-2011-07', 'ADMIN2SP-2012-04', 'ADMIN2SP-2013-04', 'ADMIN2SP-2014-10', 'ADMIN3-2021-10_left', 'ADMIN3-2021-10_left_1', 'ADMIN3-2021-10_right', 'ADMIN3-2021-10_right_1', 'ALIASES-2009-10', 'ALIASES-2011-07', 'ALIASES-2012-04', 'ALIASES-2013-04', 'ALIASES-2014-10', 'ALIASES_le-2010-07', 'ALIASES_ri-2010-07', 'COUNTRY-2009-10', 'COUNTRY-2011-07', 'COUNTRY-2012-04', 'COUNTRY-2013-04', 'COUNTRY-2014-10', 'COUNTRY_le-2010-07', 'COUNTRY_ri-2010-07', 'CS-2009-07', 'CS-2009-10', 'CS-2010-01', 'CS-2010-04', 'CS-2010-07', 'CS-2010-10', 'CS-2011-01', 'CS-2011-04', 'CS-2011-07', 'CS-2011-10', 'CS-2012-01', 'CS-2012-04', 'CS-2012-07', 'CS-2012-10', 'CS-2013-01', 'CS-2013-04', 'CS-2013-07', 'CS-2013-10', 'CS-2014-01', 'CS-2014-04', 'CS-2014-07', 'CS-2014-10', 'CS-2015-01', 'CS-2015-04', 'CS-2015-07', 'CS-2015-10', 'CS-2016-02', 'CS-2016-06', 'CS-2016-10', 'CS-2017-02', 'CS-2017-06', 'CS-2017-10', 'CS-2018-02', 'CS-2018-06', 'CS-2018-10', 'CS-2018-12', 'CS-2019-02', 'CS-2019-06', 'CS-2019-10', 'CS-2020-02', 'CS-2020-06', 'CS-2020-10', 'CS-2021-02', 'CS-2021-06', 'CS-2021-10', 'EFF_YEAR-2009-10', 'EFF_YEAR-2011-07', 'EFF_YEAR-2012-04', 'EFF_YEAR-2013-04', 'EFF_YEAR-2014-10', 'EFF_YEAR_l-2010-07', 'EFF_YEAR_r-2010-07', 'FNID-2009-10', 'FNID-2011-07', 'FNID-2012-04', 'FNID-2013-04', 'FNID-2014-10', 'FNID_left-2010-07', 'FNID_right-2010-07', 'HA-2017-02', 'HA0-2012-04', 'HA0-2012-07', 'HA0-2012-10', 'HA0-2013-01', 'HA0-2013-04', 'HA0-2013-07', 'HA0-2013-10', 'HA0-2014-01', 'HA0-2014-04', 'HA0-2014-07', 'HA0-2014-10', 'HA0-2015-01', 'HA0-2015-04', 'HA0-2015-07', 'HA0-2015-10', 'HA0-2016-02', 'HA0-2016-06', 'HA0-2016-10', 'HA0-2017-02', 'HA0-2017-06', 'HA0-2017-10', 'HA0-2018-02', 'HA0-2018-06', 'HA0-2018-10', 'HA0-2018-12', 'HA0-2019-02', 'HA0-2019-06', 'HA0-2019-10', 'HA0-2020-02', 'HA0-2020-06', 'HA0-2020-10', 'HA0-2021-02', 'HA0-2021-06', 'HA0-2021-10', 'LZCODE-2021-10_left', 'LZCODE-2021-10_left_1', 'LZCODE-2021-10_right', 'LZCODE-2021-10_right_1', 'LZNAME-2021-10_left', 'LZNAME-2021-10_left_1', 'LZNAME-2021-10_right', 'LZNAME-2021-10_right_1', 'centroid', 'country-2021-10_left', 'country-2021-10_left_1', 'country-2021-10_right', 'country-2021-10_right_1', 'cov_end-2021-10_left', 'cov_end-2021-10_left_1', 'cov_end-2021-10_right', 'cov_end-2021-10_right_1', 'cov_start-2021-10_left', 'cov_start-2021-10_left_1', 'cov_start-2021-10_right', 'cov_start-2021-10_right_1', 'geometry', 'index_ri_1-2010-07', 'index_righ-2009-10', 'index_righ-2010-07', 'index_righ-2011-07', 'index_righ-2012-04', 'index_righ-2013-04', 'index_righ-2014-10', 'report_mon-2021-10_left', 'report_mon-2021-10_left_1', 'report_mon-2021-10_right', 'report_mon-2021-10_right_1', 'unit_name-2021-10_left', 'unit_name-2021-10_left_1', 'unit_name-2021-10_right', 'unit_name-2021-10_right_1']\n"
     ]
    }
   ],
   "source": [
    "# sort columns by name\n",
    "all_fewsnet_grid = all_fewsnet_grid.reindex(sorted(all_fewsnet_grid.columns), axis=1)\n",
    "# make a list of all columns\n",
    "columnlist = all_fewsnet_grid.columns.tolist()\n",
    "print (columnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill all CS columns\n",
    "startcol = columnlist.index('CS-2009-07')\n",
    "endcol = columnlist.index('CS-2021-10') + 1\n",
    "all_fewsnet_grid.iloc[:,startcol:endcol] = all_fewsnet_grid.iloc[:,startcol:endcol].ffill(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endcol-startcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid df written to file\n"
     ]
    }
   ],
   "source": [
    "# write forward filled dfs to file\n",
    "all_fewsnet_grid_write = all_fewsnet_grid.drop(columns=['centroid'])\n",
    "all_fewsnet_grid_write = all_fewsnet_grid_write.set_geometry('geometry')\n",
    "all_fewsnet_grid_write.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_grid_write.to_file(\"./data/all_fewsnet_grid_ffill.geojson\", driver='GeoJSON')\n",
    "print(\"grid df written to file\")\n",
    "\n",
    "# all_fewsnet_centroid = all_fewsnet_grid.drop(columns=['geometry'])\n",
    "# all_fewsnet_centroid = all_fewsnet_centroid.set_geometry('centroid')\n",
    "# all_fewsnet_centroid.set_crs(epsg=4326, inplace=True)\n",
    "# all_fewsnet_centroid.to_file(\"./data/all_fewsnet_centroid_ffill.geojson\", driver='GeoJSON')\n",
    "# print(\"centroid df written to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_32272/2728579353.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  testgdf.to_file(\"./data/testgdf.shp\", driver='ESRI Shapefile')\n",
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_32272/2728579353.py:6: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  all_fewsnet_grid_write.to_file(\"./data/all_fewsnet_grid_ffill.shp\", driver='ESRI Shapefile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid df written to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3v/8xxt4zw96bn2l6qwb8w7_5r40000gn/T/ipykernel_32272/2728579353.py:14: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  all_fewsnet_centroid.to_file(\"./data/all_fewsnet_centroid_ffill.shp\", driver='ESRI Shapefile')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [142], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m all_fewsnet_centroid \u001b[39m=\u001b[39m all_fewsnet_centroid\u001b[39m.\u001b[39mset_geometry(\u001b[39m'\u001b[39m\u001b[39mcentroid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m all_fewsnet_centroid\u001b[39m.\u001b[39mset_crs(epsg\u001b[39m=\u001b[39m\u001b[39m4326\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m all_fewsnet_centroid\u001b[39m.\u001b[39;49mto_file(\u001b[39m\"\u001b[39;49m\u001b[39m./data/all_fewsnet_centroid_ffill.shp\u001b[39;49m\u001b[39m\"\u001b[39;49m, driver\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mESRI Shapefile\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcentroid df written to file\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/geodataframe.py:1216\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \n\u001b[1;32m   1135\u001b[0m \u001b[39mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39m>>> gdf.to_file('dataframe.shp', mode=\"a\")  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile\u001b[39;00m \u001b[39mimport\u001b[39;00m _to_file\n\u001b[0;32m-> 1216\u001b[0m _to_file(\u001b[39mself\u001b[39;49m, filename, driver, schema, index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/io/file.py:525\u001b[0m, in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, engine, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    519\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mColumn names longer than 10 characters will be truncated when saved to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mESRI Shapefile.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiona\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    526\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyogrio\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    527\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/io/file.py:555\u001b[0m, in \u001b[0;36m_to_file_fiona\u001b[0;34m(df, filename, driver, schema, crs, mode, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m     crs_wkt \u001b[39m=\u001b[39m crs\u001b[39m.\u001b[39mto_wkt(\u001b[39m\"\u001b[39m\u001b[39mWKT1_GDAL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    552\u001b[0m \u001b[39mwith\u001b[39;00m fiona\u001b[39m.\u001b[39mopen(\n\u001b[1;32m    553\u001b[0m     filename, mode\u001b[39m=\u001b[39mmode, driver\u001b[39m=\u001b[39mdriver, crs_wkt\u001b[39m=\u001b[39mcrs_wkt, schema\u001b[39m=\u001b[39mschema, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    554\u001b[0m ) \u001b[39mas\u001b[39;00m colxn:\n\u001b[0;32m--> 555\u001b[0m     colxn\u001b[39m.\u001b[39;49mwriterecords(df\u001b[39m.\u001b[39;49miterfeatures())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/fiona/collection.py:361\u001b[0m, in \u001b[0;36mCollection.writerecords\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    360\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcollection not open for writing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 361\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mwriterecs(records, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_len \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mget_length()\n\u001b[1;32m    363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1291\u001b[0m, in \u001b[0;36mfiona.ogrext.WritingSession.writerecs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:361\u001b[0m, in \u001b[0;36mfiona.ogrext.OGRFeatureBuilder.build\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# write testgdf to shp file\n",
    "testgdf.to_file(\"./data/testgdf.shp\", driver='ESRI Shapefile')\n",
    "all_fewsnet_grid_write = all_fewsnet_grid.drop(columns=['centroid'])\n",
    "all_fewsnet_grid_write = all_fewsnet_grid_write.set_geometry('geometry')\n",
    "all_fewsnet_grid_write.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_grid_write.to_file(\"./data/all_fewsnet_grid_ffill.shp\", driver='ESRI Shapefile')\n",
    "print(\"grid df written to file\")\n",
    "\n",
    "\n",
    "# write centroid df top geojson file\n",
    "all_fewsnet_centroid = all_fewsnet_grid.drop(columns=['geometry'])\n",
    "all_fewsnet_centroid = all_fewsnet_centroid.set_geometry('centroid')\n",
    "all_fewsnet_centroid.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_centroid.to_file(\"./data/all_fewsnet_centroid_ffill.shp\", driver='ESRI Shapefile')\n",
    "print(\"centroid df written to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from geometry and centroid columns in all_fewsnet_grid\n",
    "all_fewsnet_template = all_fewsnet_grid[['centroid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>POINT (-90.79149 14.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>POINT (-90.39149 14.98132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124059</th>\n",
       "      <td>POINT (-73.29149 18.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>POINT (-91.69149 15.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16761</th>\n",
       "      <td>POINT (-89.69149 14.28132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957849</th>\n",
       "      <td>POINT (54.20851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957850</th>\n",
       "      <td>POINT (54.20851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958503</th>\n",
       "      <td>POINT (54.30851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958504</th>\n",
       "      <td>POINT (54.30851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959157</th>\n",
       "      <td>POINT (54.40851 12.48132)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152044 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          centroid\n",
       "9573    POINT (-90.79149 14.88132)\n",
       "12190   POINT (-90.39149 14.98132)\n",
       "124059  POINT (-73.29149 18.48132)\n",
       "3697    POINT (-91.69149 15.88132)\n",
       "16761   POINT (-89.69149 14.28132)\n",
       "...                            ...\n",
       "957849   POINT (54.20851 12.48132)\n",
       "957850   POINT (54.20851 12.58132)\n",
       "958503   POINT (54.30851 12.48132)\n",
       "958504   POINT (54.30851 12.58132)\n",
       "959157   POINT (54.40851 12.48132)\n",
       "\n",
       "[152044 rows x 1 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fewsnet_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/geo/lib/python3.10/site-packages/geopandas/geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>POINT (-90.79149 14.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>POINT (-90.39149 14.98132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124059</th>\n",
       "      <td>POINT (-73.29149 18.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>POINT (-91.69149 15.88132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16761</th>\n",
       "      <td>POINT (-89.69149 14.28132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957849</th>\n",
       "      <td>POINT (54.20851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957850</th>\n",
       "      <td>POINT (54.20851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958503</th>\n",
       "      <td>POINT (54.30851 12.48132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958504</th>\n",
       "      <td>POINT (54.30851 12.58132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959157</th>\n",
       "      <td>POINT (54.40851 12.48132)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152044 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          centroid\n",
       "9573    POINT (-90.79149 14.88132)\n",
       "12190   POINT (-90.39149 14.98132)\n",
       "124059  POINT (-73.29149 18.48132)\n",
       "3697    POINT (-91.69149 15.88132)\n",
       "16761   POINT (-89.69149 14.28132)\n",
       "...                            ...\n",
       "957849   POINT (54.20851 12.48132)\n",
       "957850   POINT (54.20851 12.58132)\n",
       "958503   POINT (54.30851 12.48132)\n",
       "958504   POINT (54.30851 12.58132)\n",
       "959157   POINT (54.40851 12.48132)\n",
       "\n",
       "[152044 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set geometry of all_fewsnet_template to geometry column\n",
    "all_fewsnet_template.set_geometry('centroid', inplace=True)\n",
    "all_fewsnet_template.set_crs(epsg=4326, inplace=True)\n",
    "all_fewsnet_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all_fewsnet_template to geojson file\n",
    "all_fewsnet_template.to_file(\"./data/all_fewsnet_template_grid.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write all_fewsnet_template to geojson file\n",
    "all_fewsnet_template.to_file(\"./data/all_fewsnet_template_centroid.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the grid\n",
    "# for columns in ea_grid that end in cs if value is 88 or 99 delete that value\n",
    "# from what I can gather 88 and 99 are used to indicate missing data in FEWSNET\n",
    "# for col in ea_grid.columns:\n",
    "#     if col.endswith('-CS'):\n",
    "#         ea_grid[col] = ea_grid[col].replace(88, np.nan)\n",
    "#         ea_grid[col] = ea_grid[col].replace(99, np.nan)\n",
    "# deleting rows that are just NaN values\n",
    "ea_grid = ea_grid.dropna(axis=0, how='all', subset=ea_grid.iloc[:,3:93].columns)\n",
    "# switching geometry from centroid column to geometry column. geometry is the column containing our tile squares. \n",
    "ea_grid = ea_grid.set_geometry('geometry')\n",
    "ea_grid_nocentroid = ea_grid.drop(columns=['centroid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace columns in ea_grid with csgrid\n",
    "ea_grid = ea_grid.drop(columns=ea_grid.columns[ea_grid.columns.str.endswith('-CS')])\n",
    "ea_grid = ea_grid.join(csgrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea_grid_nocentroid = ea_grid.drop(columns=['centroid'])\n",
    "ea_grid_nocentroid.to_file(\"./data/join_experiments/ea_grid_1_bfill.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009-07',\n",
       " '2009-10',\n",
       " '2010-01',\n",
       " '2010-04',\n",
       " '2010-07',\n",
       " '2010-10',\n",
       " '2011-01',\n",
       " '2011-04',\n",
       " '2011-07',\n",
       " '2011-10',\n",
       " '2012-01',\n",
       " '2012-04',\n",
       " '2012-07',\n",
       " '2012-10',\n",
       " '2013-01',\n",
       " '2013-04',\n",
       " '2013-07',\n",
       " '2013-10',\n",
       " '2014-01',\n",
       " '2014-04',\n",
       " '2014-07',\n",
       " '2014-10',\n",
       " '2015-01',\n",
       " '2015-04',\n",
       " '2015-07',\n",
       " '2015-10',\n",
       " '2016-02',\n",
       " '2016-06',\n",
       " '2016-10',\n",
       " '2017-02',\n",
       " '2017-06',\n",
       " '2017-10',\n",
       " '2018-02',\n",
       " '2018-06',\n",
       " '2018-10',\n",
       " '2018-12',\n",
       " '2019-02',\n",
       " '2019-06',\n",
       " '2019-10',\n",
       " '2020-02',\n",
       " '2020-06',\n",
       " '2020-10',\n",
       " '2021-02',\n",
       " '2021-06',\n",
       " '2021-10']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort dateslist\n",
    "dateslist.sort()\n",
    "# remove duplicates from list\n",
    "dateslist = list(dict.fromkeys(dateslist))\n",
    "dateslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce408d48c041f753076dbaea90f671b6d136b2c04f48a62e0a991cf8ef98bfb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
